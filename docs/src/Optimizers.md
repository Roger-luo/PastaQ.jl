# Optimizers 

### Stochastic gradient descent
```@docs
SGD
update!(::LPDO,::Array,::SGD; kwargs...)
```

### Adagrad 
```@docs
AdaGrad
update!(::LPDO,::Array,::AdaGrad; kwargs...)
```

### Adadelta 
```@docs
AdaDelta
update!(::LPDO,::Array,::AdaDelta; kwargs...)
```

### Adam 
```@docs
Adam
update!(::LPDO,::Array,::Adam; kwargs...)
```

